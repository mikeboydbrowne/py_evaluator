#!/usr/bin/env python
import argparse # optparse is deprecated
import math
from itertools import islice # slicing for iterators

def word_matches(h, ref):
    return sum(1 for w in h if w in ref)

def ngram_calc(h, ref, val):
    num_grams           = len(ref) - val + 1
    num_matches         = 0.0
    num_matches_inter   = 0

    # h_list   = list(h)
    # ref_list = list(ref)

    # print h
    # print ref
    # print num_grams

    for i in range(0, num_grams, + 1):
        # for j in range(1, val, + 1):
        # print "is -" + str(ref[i:i + val]) + "- in hypothesis?"
        if ngram_in(ref[i:i + val], h) == 1:
            num_matches = num_matches + 1
            # print 'yes'
        # else:
            # print 'no'

    # print str(val) + '-gram precision = ' + str(num_matches / num_grams)

    return num_matches / num_grams

def ngram_in(ref, h):
    # print 'checking: ' + str(h)
    # print 'checking: ' + str(ref)
    num_grams  = len(h) - len(ref) + 1
    for i in range(0, num_grams, + 1):
        if ref == h[i: i + len(ref)]:
            return 1
    return 0



def bleu_calc(h, ref):

    # calculating brevity penalty
    bp = brevity_penalty(h, ref)

    # calculating the precisions of all n-gram translations
    precisions = []
    weight = 1.0 / len(ref)
    for i in range(1, len(ref), + 1):
        precisions.append(ngram_calc(h, ref, i))

    # print precisions
    ret_val = 0.0
    for p in precisions:
        if p > 0.0:
            ret_val = ret_val + weight * math.log10(p)

    # print ret_val
    # print bp * ret_val

    return ret_val

def brevity_penalty(h, ref):
    ret_val = 0.0
    if len(h) < len(ref):
        ret_val = 1.0
    else:
        ret_val = pow(math.e, (1.0 - len(ref)/len(h)))
    return ret_val

def main():
    parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
    parser.add_argument('-i', '--input', default='data/hyp1-hyp2-ref',
            help='input file (default data/hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=None, type=int,
            help='Number of hypothesis pairs to evaluate')
    # note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
    opts = parser.parse_args()

    # we create a generator and avoid loading all sentences into a list
    def sentences():
        with open(opts.input) as f:
            for pair in f:
                yield [sentence.strip().split() for sentence in pair.split(' ||| ')]

    # note: the -n option does not work in the original code
    for h1, h2, ref in islice(sentences(), opts.num_sentences):

        # setting sentences to lower case
        lower_h1    = []
        lower_h2    = []
        lower_ref   = []
        rset        = set()
        for w in h1:
            lower_h1.append(w.lower())
        for s in h2:
            lower_h2.append(s.lower())
        for t in ref:
            lower_ref.append(t.lower())

        # print lower_ref

        # calculating meteor values
        b_h1 = bleu_calc(lower_h1, lower_ref)
        b_h2 = bleu_calc(lower_h2, lower_ref)

        print(1 if b_h1 > b_h2 else # \begin{cases}
               (0 if b_h1 == b_h2
                   else -1))        # \end{cases}

# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
