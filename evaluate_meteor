#!/usr/bin/env python
import argparse # optparse is deprecated
from itertools import islice # slicing for iterators


# initializing tunable variables
a = 1.0
b = 1.0
l = 1.0

# creating a length function for iterators
def len_iterable(i):
    return sum(1 for _ in i)

# calculate precision
def precision(h, ref):
    return (sum(1 for w in h if w in ref) / len_iterable(h))

# calculate recall
def recall(h, ref):
    return (sum(1 for w in h if w in ref) / len_iterable(ref))

# calculates the METEOR value of the reference and translation
def meteor_calc(h, ref):
    return sum(1 for w in h if w in ref)

# calculates the number of word matches between the reference and translation
def word_matches(h, ref):
    return sum(1 for w in h if w in ref)

def main():
    parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
    parser.add_argument('-i', '--input', default='data/hyp1-hyp2-ref',
            help='input file (default data/hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=None, type=int,
            help='Number of hypothesis pairs to evaluate')
    # note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
    opts = parser.parse_args()

    # we create a generator and avoid loading all sentences into a list
    def sentences():
        with open(opts.input) as f:
            for pair in f:
                yield [sentence.strip().split() for sentence in pair.split(' ||| ')]

    # note: the -n option does not work in the original code
    for h1, h2, ref in islice(sentences(), opts.num_sentences):
        # calculating METEOR values
        rset = set(ref)
        l_h1 = meteor_calc(h1, rset)
        l_h2 = meteor_calc(h2, rset)

        print(1 if l_h1 > l_h2 else # \begin{cases}
                (0 if l_h1 == l_h2
                    else -1))       # \end{cases}

# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
